{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACF -- Ackerberg, Caves, Frazer\n",
    "* This time, trying joint estimation\n",
    "* Refer to ACF_simple_twostep for an easier version, which estimates $\\Phi$ first with polynomial regression, then estimates the betas with GMM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review -- Two-Step Identification Procedure:\n",
    "For a simple example, suppose $\\omega_{it} = \\rho \\omega_{it-1} + \\xi_{it}.$ Then\n",
    "$g(x) = E[x|\\omega_{it-1}] = \\rho \\omega_{it-1}.$ Assume labor is chosen after time $t-1$. Then the estimation procedure is: \n",
    "\n",
    "## (1) Regress $y_{it}$ on $\\left(k_{it}, l_{it}, m_{it}\\right)$ nonparametrically, or using a high-order polynomial, to obtain $\\hat{\\tilde \\Phi}_t\\left(k_{it}, l_{it}, m_{it}\\right).$\n",
    "\n",
    "We do this for every period to get a sequence of functions of $(k, l, m).$ These will be plugged in for $\\Phi$ in the next step. \n",
    "\n",
    "## (2) Use the following four moment conditions to estimate the parameters $\\left(\\beta_0, \\beta_k, \\beta_l, \\rho\\right):$\n",
    "\n",
    "$$\n",
    "E\\left[\\left(y_{it} - \\beta_0 - \\beta_k k_{it} - \\beta_l l_{it} - \\rho\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right) \\otimes \\begin{pmatrix} 1 \\\\ k_{it} \\\\ l_{it-1} \\\\ \\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) \\\\ \\end{pmatrix} \\right] = 0\n",
    "$$\n",
    "\n",
    "Here's where we use GMM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New version: Joint Identification\n",
    "\n",
    "Now, we include the parameters used to fit $\\Phi$ into the GMM estimation. \n",
    "We fit $\\Phi$ with a $d$-degree polynomial, and the coefficients of that polynomial are identified by moments.\n",
    "In ACF, equation (31) shows their joint estimation moment conditions: \n",
    "\n",
    "$$\n",
    "    E\\begin{bmatrix}\n",
    "    \\varepsilon_{it} \\big| \\mathcal I_{it} \\\\ \n",
    "    \\xi_{it}+\\varepsilon_{it} \\big| \\mathcal I_{it-1}                \n",
    "    \\end{bmatrix} = \n",
    "    E\\begin{bmatrix}\n",
    "    y_{it} - \\tilde\\Phi_t(k_{it}, l_{it}, m_{it}) \\;\\; \\big| \\;\\; \\mathcal I_{it} \\\\ \n",
    "    y_{it} - \\beta_0 - \\beta_k k_{it} - \\beta_l l_{it} - g\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right) \\;\\; \\big| \\;\\; \\mathcal I_{it-1}                \n",
    "    \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "where $g(\\cdot)$ is the conditional expectation of productivity and $\\mathcal I_{it}$ is the information set of firm $i$ at time $t$.  \n",
    "\n",
    "For each time t, the full $d$-degree polynomial fit of $y = \\Phi_t(k, l, m)$ will have $\\begin{pmatrix} k+d \\\\ k \\end{pmatrix}$ coefficients, where $k$ is the number of variables (in this case 3). \n",
    "\n",
    "$$\n",
    "\\Phi_t^2(k, l, m) = \\gamma_{0,0,0} + \\gamma_{1,0,0}k + \\gamma_{0,1,0}l + \\gamma_{0,0,1}m + \\gamma_{1,1,0}kl + \\gamma_{1,0,1}km + \\gamma_{0,1,1}lm + \\gamma_{2,0,0}k^2 + \\gamma_{0,2,0}l^2 + \\gamma_{0,0,2}m^2\n",
    "$$\n",
    "\n",
    "But we need to fit $\\Phi_t$ for each year. \n",
    "\n",
    "So, assuming $g(x) = \\rho x$, the vector of parameters to identify is: \n",
    "\n",
    "$$\n",
    "\\mathbf \\theta = \\left[ \\beta_0, \\beta_k, \\beta_l, \\rho, \\underbrace{\\mathbf \\gamma_{1}}_{kCd\\times 1}, ...,  \\underbrace{\\mathbf \\gamma_{T}}_{kCd\\times 1}  \\right]_{4 + T\\cdot(kCd)}\n",
    "$$\n",
    "\n",
    "The first four parameters can be identified using the moments from the \"simple\" ACF:  \n",
    "\n",
    "$$\n",
    "E\\left[\\operatorname{vec}\\left(y_{it} - \\beta_0 - \\beta_k k_{it} - \\beta_l l_{it} - \\rho\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right) \\otimes \\begin{pmatrix} 1 \\\\ k_{it} \\\\ l_{it-1} \\\\ \\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) \\\\ \\end{pmatrix} \\right] = 0\n",
    "$$\n",
    "\n",
    "Note that we will need to plug in the polynomial coefficients into the $\\Phi$ here, from our parameter guess $\\theta$. Also note that the final term with $\\Phi$ in it is used as our moment for identifying $\\rho$.\n",
    "\n",
    "The $T\\cdot(kCd)$ \"gammas\" can be estimated using the moments for linear regression, at each time period. Each of the vectors below is \"Number of firms at time t\"-by-1.\n",
    "\n",
    "$$\n",
    "\\text{Regression at t=0:}\\begin{pmatrix}\n",
    "\\mathbf 1^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    " (k_{i0})^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    " (l_{i0})^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    " (m_{i0})^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    "(k_{i0}l_{i0})^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    "\\vdots \\\\\n",
    " (l_{i0}^2)^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Regression at t=T:}\\begin{pmatrix}\n",
    "\\mathbf 1^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    " (k_{iT})^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    " (l_{iT})^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    " (m_{iT})^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    "(k_{iT}l_{iT})^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    "\\vdots \\\\\n",
    " (l_{iT}^2)^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "Here we have $T\\cdot(kCd)$ moments fo the $T\\cdot(kCd)$ \"gammas.\" \n",
    "\n",
    "# Error function implementation. \n",
    "Let $X$ denote the polynomial regression design matrix and $\\vec t$ denote the vector of times corresponding to each row in $X$. \n",
    "\n",
    "First, let $g(\\tau): \\;\\text{time}\\;\\; \\tau \\to [\\gamma_\\tau^1, \\gamma_\\tau^l, ..., \\gamma_\\tau^{(M^2)}]$ denote the \"time mapping\" for the gammas. Using this mapping, construct \n",
    "a matrix $\\Gamma = g(\\vec t)$, whose rows correspond to the gammas associated with time of that each row's observation in  $X$. \n",
    "\n",
    "Then, $\\Phi = \\operatorname{row sum}\\left(X*\\Gamma\\right)$, where $*$ denotes elementwise multiplication.  \n",
    "\n",
    "Then, to calculate the errors, let $M_\\tau$ denote a matrix of time dummies:\n",
    "\n",
    "$$\n",
    "M_\\tau = \\left[t==1 \\big| t==2 \\big| ... \\big| t == T\\right]_{Nobs \\times T}\n",
    "$$\n",
    "\n",
    "Then the GMM errors for the regression moments can be calculated using \n",
    "\n",
    "$$\n",
    "\\mathcal E_{\\mathcal N_p\\times T } = X^\\intercal\\left[\\Phi * M_\\tau \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "# Jacobian Implementation: \n",
    "The Jacobian of the regression errros with respect to $\\theta$ is: \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    0_{\\beta} & \\begin{matrix}\n",
    "    1^\\intercal\\frac{\\partial\\Phi_0}{\\partial \\gamma_0^1} & \\cdots & 1^\\intercal\\frac{\\partial\\Phi_0}{\\partial \\gamma_0^{(m_0^2)}} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    (m_0^2)^\\intercal\\frac{\\partial\\Phi_0}{\\partial \\gamma_0^1} & \\cdots & (m_0^2)^\\intercal\\frac{\\partial\\Phi_0}{\\partial \\gamma_0^{(m_0^2)}}\n",
    "    \\end{matrix} & 0 & \\cdots & 0 \\\\  0_{\\beta} &\n",
    "    0 &     \\begin{matrix}\n",
    "    1^\\intercal\\frac{\\partial\\Phi_1}{\\partial \\gamma_1^1} & \\cdots & 1^\\intercal\\frac{\\partial\\Phi_1}{\\partial \\gamma_1^{(m_1^2)}} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    (m_1^2)^\\intercal\\frac{\\partial\\Phi_1}{\\partial \\gamma_1^1} & \\cdots & (m_1^2)^\\intercal\\frac{\\partial\\Phi_1}{\\partial \\gamma_1^{(m_1^2)}}\n",
    "    \\end{matrix} & \\cdots & 0 \\\\  \\vdots &\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\  0_{\\beta} &\n",
    "    0 & 0 & \\cdots &  \\begin{matrix}\n",
    "    1^\\intercal\\frac{\\partial\\Phi_T}{\\partial \\gamma_T^T} & \\cdots & 1^\\intercal\\frac{\\partial\\Phi_T}{\\partial \\gamma_T^{(m_T^2)}} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    (m_T^2)^\\intercal\\frac{\\partial\\Phi_T}{\\partial \\gamma_T^1} & \\cdots & (m_T^2)^\\intercal\\frac{\\partial\\Phi_T}{\\partial \\gamma_T^{(m_T^2)}}\n",
    "    \\end{matrix}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Evaluating all the partial derivatives, we get\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    0_{\\beta} & X(1)^\\intercal X(1) & 0 & \\cdots & 0 \\\\  0_{\\beta} &\n",
    "    0 &     X(2)^\\intercal X(2) & \\cdots & 0 \\\\  \\vdots &\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\  0_{\\beta} &\n",
    "    0 & 0 & \\cdots &   X(T)^\\intercal X(T)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $X(\\tau)$ represents the observations of the polynomial regressors in $X$ at time $t = \\tau$. \n",
    "\n",
    "Next, let's find the Jacobian of the \"beta\" moment restrictions. The conditions are\n",
    "$$\n",
    "\\left[ \\begin{pmatrix} 1^\\intercal \\\\ \\operatorname{vec}(k_{it})^\\intercal \\\\ \\operatorname{vec}(l_{it-1})^\\intercal \\\\ \\operatorname{vec}\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right)\\right)^\\intercal \\\\ \\end{pmatrix} \\cdot  h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)  \\right]_{4\\times 1}\n",
    "$$\n",
    "where \n",
    "$$\n",
    "h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l) = \\operatorname{vec}\\left(y_{it} - \\beta_0 - \\beta_k k_{it} - \\beta_l l_{it} - \\rho\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right).\n",
    "$$\n",
    "The Jacobian is: \n",
    "\n",
    "$$\n",
    "\\left[\\frac{\\partial e\\left(\\mathbf y, \\mathbf k, \\mathbf l|\\theta\\right)}{\\partial \\theta}\\right] \\equiv\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "= \\begin{bmatrix} \\begin{bmatrix}\n",
    "1^\\intercal\\frac{ \\mathbf \\partial h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\beta_0} & 1^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\beta_k} & 1^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\beta_l} & 1^\\intercal\\frac{ \\mathbf \\partial h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\rho} \\\\\n",
    "\\operatorname{vec}(k_{it})^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_0} &\\operatorname{vec}(k_{it})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_k} &\\operatorname{vec}(k_{it})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_l} &\\operatorname{vec}(k_{it})^\\intercal  \\frac{\\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\rho} \\\\\n",
    "\\operatorname{vec}(l_{it-1})^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_0} &\\operatorname{vec}(l_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_k} &\\operatorname{vec}(l_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_l} &\\operatorname{vec}(l_{it-1})^\\intercal  \\frac{\\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\rho} \\\\\n",
    "\\operatorname{vec}(\\Phi_{it-1})^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_0} &\\operatorname{vec}(\\Phi_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_k} &\\operatorname{vec}(\\Phi_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_l} &\\operatorname{vec}(\\Phi_{it-1})^\\intercal  \\frac{\\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\rho} \n",
    "\\end{bmatrix} & \n",
    "\\begin{bmatrix}\n",
    "1^\\intercal    \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_0^1} & \\cdots & 1^\\intercal    \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_T^{(m_T^2)}} \\\\\n",
    "\\operatorname{vec}(k_{it})^\\intercal   \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_0^1} & \\cdots & \\operatorname{vec}(k_{it})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_T^{(m_T^2)}}  \\\\\n",
    "\\operatorname{vec}(l_{it-1})^\\intercal   \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_0^1} & \\cdots & \\operatorname{vec}(l_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_T^{(m_T^2)}} \\\\ \n",
    "\\operatorname{vec}\\left(\\frac{\\partial\\Phi_{it-1}}{\\partial \\gamma_0^1}\\right)^\\intercal \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l) + \\operatorname{vec}(\\Phi_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_0^1} & \\cdots & \\operatorname{vec}\\left(\\frac{\\partial\\Phi_{it-1}}{\\partial \\gamma_T^{(m_T^2)}}\\right)^\\intercal \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l) + \\operatorname{vec}(\\Phi_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_T^{(m_T^2)}}\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\begin{bmatrix} 1^\\intercal \\\\ \\operatorname{vec}(k_{it})^\\intercal \\\\ \\operatorname{vec}(l_{it-1})^\\intercal  \\\\ \\operatorname{vec}(\\Phi_{it-1})^\\intercal \\end{bmatrix}_{4\\times n} \\times \\begin{bmatrix} \\frac{\\partial \\mathbf h}{\\partial \\beta_0} & \\frac{\\partial \\mathbf h}{\\partial \\beta_k} & \\frac{\\partial \\mathbf h}{\\partial \\beta_l} & \\frac{\\partial \\mathbf h}{\\partial \\rho} & \\frac{\\partial \\mathbf h}{\\partial \\gamma_0^1} & \\frac{\\partial \\mathbf h}{\\partial \\gamma_0^k} & \\frac{\\partial \\mathbf h}{\\partial \\gamma_0^l} & \\cdots & \\frac{\\partial \\mathbf h}{\\partial \\gamma_T^{(m^2)}}  \\end{bmatrix}_{nx(4+T*\\mathcal N_p)}\n",
    "\\end{bmatrix}  \n",
    "$$\n",
    "\n",
    "\n",
    "# Calculating the derivatives of h:\n",
    "\n",
    "$$\n",
    "\\mathbf h = \\operatorname{vec}\\left(y_{it} - \\beta_0 - \\beta_k k_{it} - \\beta_l l_{it} - \\rho\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\beta_0} =  -1 + \\rho\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\beta_k} = -\\operatorname{vec}(k_{it}) + \\rho\\operatorname{vec}(k_{it-1})\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\beta_l} = -\\operatorname{vec}(l_{it}) + \\rho\\operatorname{vec}(l_{it-1})\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\rho} = \\operatorname{vec}\\left( - \\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right) \n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\gamma_0^1} = -\\rho \\frac{\\partial \\mathbf \\Phi_\\text{prev}}{\\partial \\gamma_0^1} = 1 * \\mathbf 1\\left( t_\\text{prev} == 0 \\right)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\gamma_0^k} = -\\rho \\frac{\\partial \\mathbf \\Phi_\\text{prev}}{\\partial \\gamma_0^1} = k_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == 0 \\right)\n",
    "$$\n",
    "... for arbitrary polynomial term $x$ and time $\\tau$... \n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\gamma_\\tau^x} = -\\rho \\frac{\\partial \\mathbf \\Phi_\\text{prev}}{\\partial \\gamma_0^1} = x_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == \\tau \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\begin{bmatrix} 1^\\intercal \\\\ \\operatorname{vec}(k_{it})^\\intercal \\\\ \\operatorname{vec}(l_{it-1})^\\intercal  \\\\ \\operatorname{vec}(\\Phi_{it-1})^\\intercal \\end{bmatrix}_{4\\times n} \\times \n",
    "\\begin{bmatrix} \n",
    "\\frac{\\partial \\mathbf h}{\\partial \\beta_0} & \\frac{\\partial \\mathbf h}{\\partial \\beta_k} & \\frac{\\partial \\mathbf h}{\\partial \\beta_l} & \\frac{\\partial \\mathbf h}{\\partial \\rho} & -\\rho 1 * \\mathbf 1\\left( t_\\text{prev} == 0 \\right) & -\\rho k_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == 0 \\right) & \\cdots & -\\rho x_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == \\tau \\right) & \\cdots &  -\\rho m^2_\\text{prev}*\\mathbf 1\\left(t_\\text{prev} == T\\right) \\end{bmatrix}_{n\\times(4+T*\\mathcal N_p)}\n",
    "\\end{bmatrix}  \n",
    "$$\n",
    "\n",
    "$$\n",
    "+  \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)^\\intercal \\begin{bmatrix} \n",
    "0 & 0 & 0 & 0 &  1 * \\mathbf 1\\left( t_\\text{prev} == 0 \\right) &  k_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == 0 \\right) & \\cdots &  x_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == \\tau \\right) & \\cdots &   m^2_\\text{prev}*\\mathbf 1\\left(t_\\text{prev} == T\\right) \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "We can impement this part of the Jacobian by creating a matrix of time dummies for $tprev == t$ then multiplying the polynomial design matrix constructed of $kprev, lprev, mprev$. \n",
    "\n",
    "Let $M_{t_{prev}}$ be the matrix of time dummies which, for all times $\\tau$, tells us which observations are at $tprev == \\tau$.  The part with the regression moments is then \n",
    "\n",
    "$$\n",
    "-\\rho X_{prev} * \\begin{bmatrix}\n",
    " \\mathbf 1 \\left\\{t_{prev}==0\\right\\} & \\mathbf 1 \\left\\{t_{prev}==1\\right\\} & \\cdots & \\mathbf 1 \\left\\{t_{prev}==T\\right\\} \n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from itertools import combinations_with_replacement, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data transformation/utility functions\n",
    "def df_to_dict(df):\n",
    "    dict_of_arrays = {col: df[col].to_numpy() for col in df.columns}\n",
    "    return dict_of_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../PS3_data_changedtoxlsx.xlsx\"\n",
    "cols_to_keep = [0, 2, 3, 4, 5, 6, 40, 43, 44]\n",
    "#new_names = [\"year\", \"firm_id\", \"obs\", \"ly\", \"s01\", \"s02\", \"lc\", \"ll\", \"lm\"]\n",
    "new_names = [\"t\", \"firm_id\", \"obs\", \"y\", \"s01\", \"s02\", \"k\", \"l\", \"m\"]\n",
    "#Load in the data\n",
    "df = pd.read_excel(filename, usecols=cols_to_keep)\n",
    "df.columns = new_names\n",
    "#Keep industry 1 only\n",
    "df=df[df['s01']==1]\n",
    "#Creating lagged variables\n",
    "df = df.sort_values(by=['firm_id', 't'])\n",
    "df['kprev'] = df.groupby('firm_id')['k'].shift(1)\n",
    "df['lprev'] = df.groupby('firm_id')['l'].shift(1)\n",
    "df['mprev'] = df.groupby('firm_id')['m'].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First step of coding: Write functions for the estimation of $\\tilde \\Phi_t.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This thing creates an iterator structure of tuples, used to create \n",
    "#the design matrix of polynomial interaction terms. \n",
    "def poly_terms(n_features, degree):\n",
    "    #It looks something like this\n",
    "    #(0,), (1,), (2,), (0, 0), (0, 1), etc \n",
    "    polynomial_terms = chain(\n",
    "        *(combinations_with_replacement(range(n_features), d) for d in range(1, degree+1))\n",
    "    )\n",
    "    return(polynomial_terms)\n",
    "\n",
    "#Create design matrix for the polynomial fit\n",
    "def poly_design_matrix(xvars, degree):\n",
    "    #In case there's only one variable to fit\n",
    "    if xvars.ndim == 1:\n",
    "        xvars = xvars.reshape(1, -1)\n",
    "    # Get the number of samples (n) and number of features (m) from X\n",
    "    n_samples, n_features = xvars.shape\n",
    "    # Create polynomial terms iterator\n",
    "    polynomial_terms = poly_terms(n_features, degree)\n",
    "    # Start with a column of ones for the intercept term\n",
    "    X_poly = np.ones((n_samples, 1))\n",
    "    # Generate polynomial terms and interaction terms up to 4th degree\n",
    "    for terms in  polynomial_terms:  # For degrees 1 to 4\n",
    "            X_poly = np.hstack((X_poly, np.prod(xvars[:, terms], axis=1).reshape(-1, 1)))\n",
    "    return X_poly\n",
    "\n",
    "#Create the matrix MT, which is used for year-by-year evaluation of the regression moments. \n",
    "def time_indexing(df, X_poly, degree = 2):\n",
    "    #Times and indexing\n",
    "    times = np.unique(df['t']) #get unique times in the sample\n",
    "    T = len(times) #Number of unique times in the sample\n",
    "    NPolyTerms= X_poly.shape[1] #Number of terms in the polynomial\n",
    "    time_to_index = {time: idx for idx, time in enumerate(times)} # Create a dictionary mapping time values to the row index in G\n",
    "    #Create a Nobs*T matrix of time dummies, used to create the error terms for GMM\n",
    "    # Initialize the dummy matrix\n",
    "    time_dummies = np.zeros((X_poly.shape[0], T))\n",
    "    for i, t in enumerate(df['t']):\n",
    "        time_index = np.where(times == t)[0][0]  # Find the index of the time in unique_times\n",
    "        time_dummies[i, time_index] = 1\n",
    "    return T, NPolyTerms, times, time_to_index, time_dummies   \n",
    "    \n",
    "#creates the first term in the moment restrictions:\n",
    "def moment_error_ACF(theta, df, X_poly, degree = 2):\n",
    "    Nobs = df.shape[0]\n",
    "    #Get useful indexes\n",
    "    T, NPolyTerms, times, time_to_index, time_dummies = time_indexing(df, X_poly, degree=2)\n",
    "    #Reshape parameters theta. \n",
    "    betas = theta[:4] #extract beta_0, beta_k, beta_l, and rho\n",
    "    gammas = theta[4:] #extract the guesses for the polynomial fit coefficeints (gammas).\n",
    "    #Reshaope the gammas into a dictionary, indexed by time t of the observations. \n",
    "    Gamma_1_to_T = gammas.reshape(T, NPolyTerms) #This fills rows with K observations, then columns. \n",
    "    #Now, construct a mapping from GAMMA, whose rows are indexed by T, to the times in the sample\n",
    "    GAMMA = np.vstack([Gamma_1_to_T[time_to_index[t]] for t in df['t']])\n",
    "    #Now, evaluate Phi given the thetas.\n",
    "    #To do this, elementwise-multiply the X with the polynomal coefficients in GAMMA. Sum the rows. \n",
    "    df['Phi'] = np.sum(X_poly*GAMMA, axis = 1)\n",
    "    y_minus_Phi = df['y'] - df['Phi']\n",
    "    PHI = np.repeat(y_minus_Phi.to_numpy()[:, np.newaxis], 10, axis=1)\n",
    "    #Matrix of errors corresponding with regression moments (Nobs x T)\n",
    "    Epsilon = (X_poly).T @ (PHI*time_dummies)\n",
    "    #Lagged values of Phi\n",
    "    df['Phiprev'] = df.groupby('firm_id')['Phi'].shift(1)\n",
    "    #Now calculate the moment restrictions vector for the betas. \n",
    "    moments_betas = (df['y'] - theta[0] - theta[1]*df['k'] - theta[2]*df['l'] - \n",
    "             theta[3]*(df['Phiprev'] - theta[0] - theta[1]*df['kprev'] - theta[2]*df['lprev'] ) )\n",
    "    #remove nans (associated with the lag) -- this is ok because we're just using this vector as part of a dot product. \n",
    "    moments_betas = np.nan_to_num(moments_betas, nan = 0)\n",
    "    #Matrix of exclusion restrictions\n",
    "    Vex = np.nan_to_num(np.vstack([\n",
    "        np.ones(Nobs), \n",
    "        df['k'].to_numpy(), \n",
    "        df['lprev'].to_numpy(),\n",
    "        df['Phiprev'].to_numpy()\n",
    "    ]),  nan=0)\n",
    "    #Evaluate the errors\n",
    "    err_betas = Vex@moments_betas\n",
    "    #Put together all of the errors into a single vector. \n",
    "    #Here, we want to unravel the Epsilon matrix so gammas are sorted into vectors by t. \n",
    "    epsilons = Epsilon.reshape(Epsilon.size)\n",
    "    error_vec = np.concatenate((err_betas, epsilons))\n",
    "    return error_vec\n",
    "\n",
    "def gmm_obj_ACF(theta, df, X_poly, W):\n",
    "    #Arguments\n",
    "    #Get the vector h(theta, y, k, l)\n",
    "    moment_error = moment_error_ACF(theta, df, X_poly, degree)\n",
    "    #Calculate the weighted sum of the error using the weight matrix, W\n",
    "    obj = moment_error.T@W@moment_error\n",
    "    return obj\n",
    "\n",
    "def jac_ACF(theta, df, X_poly, W):\n",
    "    #Arguments\n",
    "    xvars_prev = df[['kprev', 'lprev', 'mprev']].to_numpy()\n",
    "    X_poly = poly_design_matrix(xvars, degree)\n",
    "    #Get the vector h(theta, y, k, l)\n",
    "    moment_error = moment_error_ACF(theta, df, X_poly, degree)\n",
    "    #Calculate the weighted sum of the error using the weight matrix, W\n",
    "    obj = moment_error.T@W@moment_error\n",
    "    return obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create polynomial design matrix\n",
    "degree = 2\n",
    "xvars = df[['k', 'l', 'm']].to_numpy()\n",
    "X_poly = poly_design_matrix(xvars, degree)\n",
    "#Get time dimension and number of polynomial terms \n",
    "T, NPolyTerms, times, time_to_index, time_dummies  = time_indexing(df, X_poly, degree)\n",
    "#Initial guess for theta -- size depends on the degree of the polynomial and the number of times (number of phi_t fits)\n",
    "theta0= np.ones(4+T*NPolyTerms)\n",
    "W0 = np.eye(theta0.size)\n",
    "#get error vector\n",
    "error_vec = moment_error_ACF(theta0, df, X_poly, degree)\n",
    "#Get gmm objective function error\n",
    "error_obj = gmm_obj_ACF(theta0, df, X_poly, W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step --  need to calculate the gradient to perform optimization. \n",
    "\n",
    "The gradient of the GMM objective function with respect to the parameters $\\theta$ is\n",
    "$$\n",
    "\\nabla_{\\theta}  \\mathbf e\\left(\\mathbf y, \\mathbf k, \\mathbf l|\\theta\\right)^\\intercal_{1\\times 4} \\times\\left(\\mathbb W_{4\\times 4}\\right) \\times      \\mathbf e\\left(\\mathbf y, \\mathbf k, \\mathbf l|\\theta\\right)_{4\\times 1} \\equiv 2\\left[\\frac{\\partial e\\left(\\mathbf y, \\mathbf k, \\mathbf l|\\theta\\right)}{\\partial \\theta}\\right]^\\intercal_{4\\times 4}\\times\\left(\\mathbb W_{4\\times 4}\\right) \\times      \\mathbf e\\left(\\mathbf y, \\mathbf k, \\mathbf l|\\theta\\right)_{4\\times 1}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\left[\\frac{\\partial e\\left(\\mathbf y, \\mathbf k, \\mathbf l|\\theta\\right)}{\\partial \\theta}\\right]_{4\\times 4} = \\begin{bmatrix} \n",
    "1^\\intercal\\frac{ \\mathbf \\partial h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\beta_0} & 1^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\beta_k} & 1^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\beta_l} & 1^\\intercal\\frac{ \\mathbf \\partial h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\rho} \\\\\n",
    "\\operatorname{vec}(k_{it})^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_0} &\\operatorname{vec}(k_{it})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_k} &\\operatorname{vec}(k_{it})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_l} &\\operatorname{vec}(k_{it})^\\intercal  \\frac{\\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\rho} \\\\\n",
    "\\operatorname{vec}(l_{it-1})^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_0} &\\operatorname{vec}(l_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_k} &\\operatorname{vec}(l_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_l} &\\operatorname{vec}(l_{it-1})^\\intercal  \\frac{\\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\rho} \\\\\n",
    "\\operatorname{vec}(\\Phi_{it-1})^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_0} &\\operatorname{vec}(\\Phi_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_k} &\\operatorname{vec}(\\Phi_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_l} &\\operatorname{vec}(\\Phi_{it-1})^\\intercal  \\frac{\\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\rho} \n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\equiv \\begin{bmatrix} 1^\\intercal \\\\ \\operatorname{vec}(k_{it})^\\intercal \\\\ \\operatorname{vec}(l_{it-1})^\\intercal  \\\\ \\operatorname{vec}(\\Phi_{it-1})^\\intercal \\end{bmatrix}_{4\\times n} \\begin{bmatrix} \\frac{\\partial \\mathbf h}{\\partial \\beta_0} & \\frac{\\partial \\mathbf h}{\\partial \\beta_k} & \\frac{\\partial \\mathbf h}{\\partial \\beta_l} & \\frac{\\partial \\mathbf h}{\\partial \\rho}  \\end{bmatrix}_{4x4}\n",
    "$$\n",
    "\n",
    "\n",
    "is the Jacobian of the error function with respect to $\\theta = \\left(\\beta_0, \\beta_k, \\beta_l, \\rho\\right)$. \n",
    "\n",
    "We already have code to calculate the first matrix here -- it is just called ```Vex```, \"vectors of exogeneity restrictions.\"\n",
    "It remains to calculate the partial derivatives in the second matrix.\n",
    "\n",
    "$$\n",
    "\\mathbf h = \\operatorname{vec}\\left(y_{it} - \\beta_0 - \\beta_k k_{it} - \\beta_l l_{it} - \\rho\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\beta_0} =  -1 + \\rho\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\beta_k} = -\\operatorname{vec}(k_{it}) + \\rho\\operatorname{vec}(k_{it-1})\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\beta_l} = -\\operatorname{vec}(l_{it}) + \\rho\\operatorname{vec}(l_{it-1})\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\rho} = \\operatorname{vec}\\left( - \\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right) \n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_ACF(theta, args, Vex):\n",
    "    y, Phi, Phiprev, k, kprev, l, lprev = args\n",
    "    \n",
    "    #Partial derivatives of h\n",
    "    Dh = np.nan_to_num(np.vstack(\n",
    "        [\n",
    "         np.ones(len(k))*(-1 + theta[3]), #dh/dbeta0  \n",
    "         -k + theta[3]*kprev,             #dh/dbetak\n",
    "         -l + theta[3]*lprev,             #dh/dbetal\n",
    "         -(Phiprev - theta[0] - theta[1]*kprev - theta[2]*lprev)\n",
    "        ]\n",
    "    ),  nan=0).T\n",
    "\n",
    "    Jac = Vex@Dh\n",
    "    return Jac\n",
    "\n",
    "\n",
    "def gradient_ACF(theta, args, Vex, W):\n",
    "    moment_error = moment_error_ACF(theta, args)\n",
    "    err = Vex@moment_error\n",
    "    Jac = jacobian_ACF(theta, args, Vex)\n",
    "    Grad = (2*Jac.T @ W @ err)\n",
    "    return Grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  4.21897327e+06, -1.15537652e+04, -2.73682493e+07])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "Jac = jacobian_ACF(theta0, args_ACF, Vex)\n",
    "Jac\n",
    "Grad = gradient_ACF(theta0, args_ACF, Vex, W0)\n",
    "Grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, use a minimization routine, with the Jacobian, to optimize for theta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010508466106636766"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_ACF = format_args_ACF(df)\n",
    "gmm_args = (args_ACF, Vex, W0)\n",
    "\n",
    "#Solving using my own gradient\n",
    "theta_results_grad = opt.minimize(gmm_obj_ACF, theta0, args=gmm_args,\n",
    "                       tol=1e-14, jac=gradient_ACF, method='L-BFGS-B')\n",
    "#Solving without providing a gradient\n",
    "theta_results_nograd = opt.minimize(gmm_obj_ACF, theta0, args=gmm_args,\n",
    "                        tol=1e-14, method='L-BFGS-B')\n",
    "theta_results_grad.x, theta_results_nograd.x\n",
    "theta_results = theta_results_grad.x\n",
    "\n",
    "gmm_obj_ACF(theta_results, args_ACF, Vex, W0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
