{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACF -- Ackerberg, Caves, Frazer\n",
    "* This time, trying joint estimation\n",
    "* Refer to ACF_simple_twostep for an easier version, which estimates $\\Phi$ first with polynomial regression, then estimates the betas with GMM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review -- Two-Step Identification Procedure:\n",
    "For a simple example, suppose $\\omega_{it} = \\rho \\omega_{it-1} + \\xi_{it}.$ Then\n",
    "$g(x) = E[x|\\omega_{it-1}] = \\rho \\omega_{it-1}.$ Assume labor is chosen after time $t-1$. Then the estimation procedure is: \n",
    "\n",
    "## (1) Regress $y_{it}$ on $\\left(k_{it}, l_{it}, m_{it}\\right)$ nonparametrically, or using a high-order polynomial, to obtain $\\hat{\\tilde \\Phi}_t\\left(k_{it}, l_{it}, m_{it}\\right).$\n",
    "\n",
    "We do this for every period to get a sequence of functions of $(k, l, m).$ These will be plugged in for $\\Phi$ in the next step. \n",
    "\n",
    "## (2) Use the following four moment conditions to estimate the parameters $\\left(\\beta_0, \\beta_k, \\beta_l, \\rho\\right):$\n",
    "\n",
    "$$\n",
    "E\\left[\\left(y_{it} - \\beta_0 - \\beta_k k_{it} - \\beta_l l_{it} - \\rho\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right) \\otimes \\begin{pmatrix} 1 \\\\ k_{it} \\\\ l_{it-1} \\\\ \\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) \\\\ \\end{pmatrix} \\right] = 0\n",
    "$$\n",
    "\n",
    "Here's where we use GMM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New version: Joint Identification\n",
    "\n",
    "Now, we include the parameters used to fit $\\Phi$ into the GMM estimation. \n",
    "We fit $\\Phi$ with a $d$-degree polynomial, and the coefficients of that polynomial are identified by moments.\n",
    "In ACF, equation (31) shows their joint estimation moment conditions: \n",
    "\n",
    "$$\n",
    "    E\\begin{bmatrix}\n",
    "    \\varepsilon_{it} \\big| \\mathcal I_{it} \\\\ \n",
    "    \\xi_{it}+\\varepsilon_{it} \\big| \\mathcal I_{it-1}                \n",
    "    \\end{bmatrix} = \n",
    "    E\\begin{bmatrix}\n",
    "    y_{it} - \\tilde\\Phi_t(k_{it}, l_{it}, m_{it}) \\;\\; \\big| \\;\\; \\mathcal I_{it} \\\\ \n",
    "    y_{it} - \\beta_0 - \\beta_k k_{it} - \\beta_l l_{it} - g\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right) \\;\\; \\big| \\;\\; \\mathcal I_{it-1}                \n",
    "    \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "where $g(\\cdot)$ is the conditional expectation of productivity and $\\mathcal I_{it}$ is the information set of firm $i$ at time $t$.  \n",
    "\n",
    "For each time t, the full $d$-degree polynomial fit of $y = \\Phi_t(k, l, m)$ will have $\\begin{pmatrix} k+d \\\\ k \\end{pmatrix}$ coefficients, where $k$ is the number of variables (in this case 3). \n",
    "\n",
    "$$\n",
    "\\Phi_t^2(k, l, m) = \\gamma_{0,0,0} + \\gamma_{1,0,0}k + \\gamma_{0,1,0}l + \\gamma_{0,0,1}m + \\gamma_{1,1,0}kl + \\gamma_{1,0,1}km + \\gamma_{0,1,1}lm + \\gamma_{2,0,0}k^2 + \\gamma_{0,2,0}l^2 + \\gamma_{0,0,2}m^2\n",
    "$$\n",
    "\n",
    "But we need to fit $\\Phi_t$ for each year. \n",
    "\n",
    "So, assuming $g(x) = \\rho x$, the vector of parameters to identify is: \n",
    "\n",
    "$$\n",
    "\\mathbf \\theta = \\left[ \\beta_0, \\beta_k, \\beta_l, \\rho, \\underbrace{\\mathbf \\gamma_{1}}_{kCd\\times 1}, ...,  \\underbrace{\\mathbf \\gamma_{T}}_{kCd\\times 1}  \\right]_{4 + T\\cdot(kCd)}\n",
    "$$\n",
    "\n",
    "The first four parameters can be identified using the moments from the \"simple\" ACF:  \n",
    "\n",
    "$$\n",
    "E\\left[\\operatorname{vec}\\left(y_{it} - \\beta_0 - \\beta_k k_{it} - \\beta_l l_{it} - \\rho\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right) \\otimes \\begin{pmatrix} 1 \\\\ k_{it} \\\\ l_{it-1} \\\\ \\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) \\\\ \\end{pmatrix} \\right] = 0\n",
    "$$\n",
    "\n",
    "Note that we will need to plug in the polynomial coefficients into the $\\Phi$ here, from our parameter guess $\\theta$. Also note that the final term with $\\Phi$ in it is used as our moment for identifying $\\rho$.\n",
    "\n",
    "The $T\\cdot(kCd)$ \"gammas\" can be estimated using the moments for linear regression, at each time period. Each of the vectors below is \"Number of firms at time t\"-by-1.\n",
    "\n",
    "$$\n",
    "\\text{Regression at t=0:}\\begin{pmatrix}\n",
    "\\mathbf 1^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    " (k_{i0})^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    " (l_{i0})^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    " (m_{i0})^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    "(k_{i0}l_{i0})^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    "\\vdots \\\\\n",
    " (l_{i0}^2)^\\intercal \\left[ y_{i0} - \\tilde\\Phi_0(k_{i0}, l_{i0}, m_{i0})  \\right] \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Regression at t=T:}\\begin{pmatrix}\n",
    "\\mathbf 1^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    " (k_{iT})^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    " (l_{iT})^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    " (m_{iT})^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    "(k_{iT}l_{iT})^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    "\\vdots \\\\\n",
    " (l_{iT}^2)^\\intercal \\left[ y_{iT} - \\tilde\\Phi_T(k_{iT}, l_{iT}, m_{iT})  \\right] \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "Here we have $T\\cdot(kCd)$ moments fo the $T\\cdot(kCd)$ \"gammas.\" \n",
    "\n",
    "# Error function implementation. \n",
    "Let $X$ denote the polynomial regression design matrix and $\\vec t$ denote the vector of times corresponding to each row in $X$. \n",
    "\n",
    "First, let $g(\\tau): \\;\\text{time}\\;\\; \\tau \\to [\\gamma_\\tau^1, \\gamma_\\tau^l, ..., \\gamma_\\tau^{(M^2)}]$ denote the \"time mapping\" for the gammas. Using this mapping, construct \n",
    "a matrix $\\Gamma = g(\\vec t)$, whose rows correspond to the gammas associated with time of that each row's observation in  $X$. \n",
    "\n",
    "Then, $\\Phi = \\operatorname{row sum}\\left(X*\\Gamma\\right)$, where $*$ denotes elementwise multiplication.  \n",
    "\n",
    "Then, to calculate the errors for the regression moments, let $M_\\tau$ denote a matrix of time dummies:\n",
    "\n",
    "$$\n",
    "M_\\tau = \\left[t==1 \\big| t==2 \\big| ... \\big| t == T\\right]_{Nobs \\times T}\n",
    "$$\n",
    "\n",
    "We use this matrix to set equal to zero any observations that do not correspond with the current time. \n",
    "\n",
    "Then the GMM errors for the regression moments can be calculated using \n",
    "\n",
    "$$\n",
    "\\mathcal E_{\\mathcal N_p\\times T } = \\left[\\left(Y - \\Phi\\right) * M_\\tau \\right]^\\intercal X = \\begin{bmatrix}\n",
    "1^\\intercal\\left[\\left(Y-\\Phi\\right)\\mathbf 1\\left\\{t=1\\right\\}\\right] & \\cdots & (m^2)^\\intercal\\left[\\left(Y-\\Phi\\right)\\mathbf 1\\left\\{t=1\\right\\} \\right] \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "1^\\intercal\\left[\\left(Y-\\Phi\\right)\\mathbf 1\\left\\{t=T\\right\\}\\right] & \\cdots & (m^2)^\\intercal\\left[\\left(Y-\\Phi\\right)\\mathbf 1\\left\\{t=T\\right\\} \\right] \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $Y$ is the vector of $y_{it}$ observations.We then \"unravel\" that matrix row-by-row into a vector, which is $\\left(T\\cdot \\mathcal N_p\\right)\\times 1$, the same length as the total number of gammas. $\\mathcal N_p = kCd$ is the number of polynomial terms.\n",
    "\n",
    "To get the errors for the \"beta\" moments, follow the same procedure as in the two-step ACF. \n",
    "\n",
    "\n",
    "# Jacobian Implementation: \n",
    "Note -- my notation is inconsistent, here I am denoting the first time as time 0. The Jacobian of the regression errros with respect to $\\theta$ is: \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    0_{\\beta} & \\begin{matrix}\n",
    "    1^\\intercal\\frac{\\partial\\Phi_0}{\\partial \\gamma_0^1} & \\cdots & 1^\\intercal\\frac{\\partial\\Phi_0}{\\partial \\gamma_0^{(m_0^2)}} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    (m_0^2)^\\intercal\\frac{\\partial\\Phi_0}{\\partial \\gamma_0^1} & \\cdots & (m_0^2)^\\intercal\\frac{\\partial\\Phi_0}{\\partial \\gamma_0^{(m_0^2)}}\n",
    "    \\end{matrix} & 0 & \\cdots & 0 \\\\  0_{\\beta} &\n",
    "    0 &     \\begin{matrix}\n",
    "    1^\\intercal\\frac{\\partial\\Phi_1}{\\partial \\gamma_1^1} & \\cdots & 1^\\intercal\\frac{\\partial\\Phi_1}{\\partial \\gamma_1^{(m_1^2)}} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    (m_1^2)^\\intercal\\frac{\\partial\\Phi_1}{\\partial \\gamma_1^1} & \\cdots & (m_1^2)^\\intercal\\frac{\\partial\\Phi_1}{\\partial \\gamma_1^{(m_1^2)}}\n",
    "    \\end{matrix} & \\cdots & 0 \\\\  \\vdots &\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\  0_{\\beta} &\n",
    "    0 & 0 & \\cdots &  \\begin{matrix}\n",
    "    1^\\intercal\\frac{\\partial\\Phi_T}{\\partial \\gamma_T^T} & \\cdots & 1^\\intercal\\frac{\\partial\\Phi_T}{\\partial \\gamma_T^{(m_T^2)}} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    (m_T^2)^\\intercal\\frac{\\partial\\Phi_T}{\\partial \\gamma_T^1} & \\cdots & (m_T^2)^\\intercal\\frac{\\partial\\Phi_T}{\\partial \\gamma_T^{(m_T^2)}}\n",
    "    \\end{matrix}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Evaluating all the partial derivatives, we get\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    0_{\\beta} & X(1)^\\intercal X(1) & 0 & \\cdots & 0 \\\\  0_{\\beta} &\n",
    "    0 &     X(2)^\\intercal X(2) & \\cdots & 0 \\\\  \\vdots &\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\  0_{\\beta} &\n",
    "    0 & 0 & \\cdots &   X(T)^\\intercal X(T)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $X(\\tau)$ represents the observations of the polynomial regressors in $X$ at time $t = \\tau$. \n",
    "\n",
    "Next, let's find the Jacobian of the \"beta\" moment restrictions. The conditions are\n",
    "$$\n",
    "\\left[ \\begin{pmatrix} 1^\\intercal \\\\ \\operatorname{vec}(k_{it})^\\intercal \\\\ \\operatorname{vec}(l_{it-1})^\\intercal \\\\ \\operatorname{vec}\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right)\\right)^\\intercal \\\\ \\end{pmatrix} \\cdot  h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)  \\right]_{4\\times 1}\n",
    "$$\n",
    "where \n",
    "$$\n",
    "h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l) = \\operatorname{vec}\\left(y_{it} - \\beta_0 - \\beta_k k_{it} - \\beta_l l_{it} - \\rho\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right).\n",
    "$$\n",
    "The Jacobian is: \n",
    "\n",
    "$$\n",
    "\\left[\\frac{\\partial e\\left(\\mathbf y, \\mathbf k, \\mathbf l|\\theta\\right)}{\\partial \\theta}\\right] \\equiv\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "= \\begin{bmatrix} \\begin{bmatrix}\n",
    "1^\\intercal\\frac{ \\mathbf \\partial h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\beta_0} & 1^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\beta_k} & 1^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\beta_l} & 1^\\intercal\\frac{ \\mathbf \\partial h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)}{\\partial \\rho} \\\\\n",
    "\\operatorname{vec}(k_{it})^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_0} &\\operatorname{vec}(k_{it})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_k} &\\operatorname{vec}(k_{it})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_l} &\\operatorname{vec}(k_{it})^\\intercal  \\frac{\\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\rho} \\\\\n",
    "\\operatorname{vec}(l_{it-1})^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_0} &\\operatorname{vec}(l_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_k} &\\operatorname{vec}(l_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_l} &\\operatorname{vec}(l_{it-1})^\\intercal  \\frac{\\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\rho} \\\\\n",
    "\\operatorname{vec}(\\Phi_{it-1})^\\intercal\\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_0} &\\operatorname{vec}(\\Phi_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_k} &\\operatorname{vec}(\\Phi_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\beta_l} &\\operatorname{vec}(\\Phi_{it-1})^\\intercal  \\frac{\\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\rho} \n",
    "\\end{bmatrix} & \n",
    "\\begin{bmatrix}\n",
    "1^\\intercal    \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_0^1} & \\cdots & 1^\\intercal    \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_T^{(m_T^2)}} \\\\\n",
    "\\operatorname{vec}(k_{it})^\\intercal   \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_0^1} & \\cdots & \\operatorname{vec}(k_{it})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_T^{(m_T^2)}}  \\\\\n",
    "\\operatorname{vec}(l_{it-1})^\\intercal   \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_0^1} & \\cdots & \\operatorname{vec}(l_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_T^{(m_T^2)}} \\\\ \n",
    "\\operatorname{vec}\\left(\\frac{\\partial\\Phi_{it-1}}{\\partial \\gamma_0^1}\\right)^\\intercal \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l) + \\operatorname{vec}(\\Phi_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_0^1} & \\cdots & \\operatorname{vec}\\left(\\frac{\\partial\\Phi_{it-1}}{\\partial \\gamma_T^{(m_T^2)}}\\right)^\\intercal \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l) + \\operatorname{vec}(\\Phi_{it-1})^\\intercal \\frac{ \\partial \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)\n",
    "}{\\partial \\mathbf \\gamma_T^{(m_T^2)}}\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\begin{bmatrix} 1^\\intercal \\\\ \\operatorname{vec}(k_{it})^\\intercal \\\\ \\operatorname{vec}(l_{it-1})^\\intercal  \\\\ \\operatorname{vec}(\\Phi_{it-1})^\\intercal \\end{bmatrix}_{4\\times n} \\times \\begin{bmatrix} \\frac{\\partial \\mathbf h}{\\partial \\beta_0} & \\frac{\\partial \\mathbf h}{\\partial \\beta_k} & \\frac{\\partial \\mathbf h}{\\partial \\beta_l} & \\frac{\\partial \\mathbf h}{\\partial \\rho} & \\frac{\\partial \\mathbf h}{\\partial \\gamma_0^1} & \\frac{\\partial \\mathbf h}{\\partial \\gamma_0^k} & \\frac{\\partial \\mathbf h}{\\partial \\gamma_0^l} & \\cdots & \\frac{\\partial \\mathbf h}{\\partial \\gamma_T^{(m^2)}}  \\end{bmatrix}_{nx(4+T*\\mathcal N_p)}\n",
    "\\end{bmatrix}  \n",
    "$$\n",
    "\n",
    "\n",
    "# Calculating the derivatives of h:\n",
    "\n",
    "$$\n",
    "\\mathbf h = \\operatorname{vec}\\left(y_{it} - \\beta_0 - \\beta_k k_{it} - \\beta_l l_{it} - \\rho\\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\beta_0} =  -1 + \\rho\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\beta_k} = -\\operatorname{vec}(k_{it}) + \\rho\\operatorname{vec}(k_{it-1})\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\beta_l} = -\\operatorname{vec}(l_{it}) + \\rho\\operatorname{vec}(l_{it-1})\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\rho} = \\operatorname{vec}\\left( - \\left(\\tilde \\Phi_{t-1}\\left(k_{it-1}, l_{it-1}, m_{it-1}\\right) - \\beta_0 - \\beta_k k_{it-1} - \\beta_l l_{it-1}\\right)\\right) \n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\gamma_0^1} = -\\rho \\frac{\\partial \\mathbf \\Phi_\\text{prev}}{\\partial \\gamma_0^1} = 1 * \\mathbf 1\\left( t_\\text{prev} == 0 \\right)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\gamma_0^k} = -\\rho \\frac{\\partial \\mathbf \\Phi_\\text{prev}}{\\partial \\gamma_0^1} = k_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == 0 \\right)\n",
    "$$\n",
    "... for arbitrary polynomial term $x$ and time $\\tau$... \n",
    "$$\n",
    "\\frac{\\partial \\mathbf h}{\\partial \\gamma_\\tau^x} = -\\rho \\frac{\\partial \\mathbf \\Phi_\\text{prev}}{\\partial \\gamma_0^1} = x_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == \\tau \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\begin{bmatrix} 1^\\intercal \\\\ \\operatorname{vec}(k_{it})^\\intercal \\\\ \\operatorname{vec}(l_{it-1})^\\intercal  \\\\ \\operatorname{vec}(\\Phi_{it-1})^\\intercal \\end{bmatrix}_{4\\times n} \\times \n",
    "\\begin{bmatrix} \n",
    "\\frac{\\partial \\mathbf h}{\\partial \\beta_0} & \\frac{\\partial \\mathbf h}{\\partial \\beta_k} & \\frac{\\partial \\mathbf h}{\\partial \\beta_l} & \\frac{\\partial \\mathbf h}{\\partial \\rho} & -\\rho 1 * \\mathbf 1\\left( t_\\text{prev} == 0 \\right) & -\\rho k_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == 0 \\right) & \\cdots & -\\rho x_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == \\tau \\right) & \\cdots &  -\\rho m^2_\\text{prev}*\\mathbf 1\\left(t_\\text{prev} == T\\right) \\end{bmatrix}_{n\\times(4+T*\\mathcal N_p)}\n",
    "\\end{bmatrix}  \n",
    "$$\n",
    "\n",
    "$$\n",
    "+  \\mathbf h(\\theta, \\mathbf y, \\mathbf k, \\mathbf l)^\\intercal \\begin{bmatrix} \n",
    "0 & 0 & 0 & 0 &  1 * \\mathbf 1\\left( t_\\text{prev} == 0 \\right) &  k_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == 0 \\right) & \\cdots &  x_\\text{prev} * \\mathbf 1\\left( t_\\text{prev} == \\tau \\right) & \\cdots &   m^2_\\text{prev}*\\mathbf 1\\left(t_\\text{prev} == T\\right) \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "We can impement this part of the Jacobian by creating a matrix of time dummies for $tprev == t$ then multiplying the polynomial design matrix constructed of $kprev, lprev, mprev$. \n",
    "\n",
    "Let $M_{t_{prev}}$ be the matrix of time dummies which, for all times $\\tau$, tells us which observations are at $tprev == \\tau$.  The part with the regression moments is then \n",
    "\n",
    "$$\n",
    "-\\rho X_{prev} * \\begin{bmatrix}\n",
    " \\mathbf 1 \\left\\{t_{prev}==0\\right\\} & \\mathbf 1 \\left\\{t_{prev}==1\\right\\} & \\cdots & \\mathbf 1 \\left\\{t_{prev}==T\\right\\} \n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from itertools import combinations_with_replacement, chain\n",
    "from scipy.linalg import block_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data transformation/utility functions\n",
    "def df_to_dict(df):\n",
    "    dict_of_arrays = {col: df[col].to_numpy() for col in df.columns}\n",
    "    return dict_of_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../PS3_data_changedtoxlsx.xlsx\"\n",
    "df0 = pd.read_excel(filename)\n",
    "\n",
    "\n",
    "df = df0[['year', 'firm_id', 'X03', 'X04', 'X05', 'X40', 'X43', 'X44']]\n",
    "#new_names = [\"year\", \"firm_id\", \"obs\", \"ly\", \"s01\", \"s02\", \"lc\", \"ll\", \"lm\"]\n",
    "new_names = [\"t\", \"firm_id\", \"y\", \"s01\", \"s02\", \"k\", \"l\", \"m\"]\n",
    "\n",
    "df.columns = new_names\n",
    "#Keep industry 1 only\n",
    "df=df[df['s02']==1]\n",
    "#Creating lagged variables\n",
    "df = df.sort_values(by=['firm_id', 't'])\n",
    "df['kprev'] = df.groupby('firm_id')['k'].shift(1)\n",
    "df['lprev'] = df.groupby('firm_id')['l'].shift(1)\n",
    "df['mprev'] = df.groupby('firm_id')['m'].shift(1)\n",
    "df['tprev'] = df.groupby('firm_id')['t'].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First step of coding: Write functions for the estimation of $\\tilde \\Phi_t.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This thing creates an iterator structure of tuples, used to create \n",
    "#the design matrix of polynomial interaction terms. \n",
    "def poly_terms(n_features, degree):\n",
    "    #It looks something like this\n",
    "    #(0,), (1,), (2,), (0, 0), (0, 1), etc \n",
    "    polynomial_terms = chain(\n",
    "        *(combinations_with_replacement(range(n_features), d) for d in range(1, degree+1))\n",
    "    )\n",
    "    return(polynomial_terms)\n",
    "\n",
    "#Create design matrix for the polynomial fit\n",
    "def poly_design_matrix(xvars, degree):\n",
    "    #In case there's only one variable to fit\n",
    "    if xvars.ndim == 1:\n",
    "        xvars = xvars.reshape(1, -1)\n",
    "    # Get the number of samples (n) and number of features (m) from X\n",
    "    n_samples, n_features = xvars.shape\n",
    "    # Create polynomial terms iterator\n",
    "    polynomial_terms = poly_terms(n_features, degree)\n",
    "    # Start with a column of ones for the intercept term\n",
    "    X_poly = np.ones((n_samples, 1))\n",
    "    # Generate polynomial terms and interaction terms up to 4th degree\n",
    "    for terms in  polynomial_terms:  # For degrees 1 to 4\n",
    "            X_poly = np.hstack((X_poly, np.prod(xvars[:, terms], axis=1).reshape(-1, 1)))\n",
    "    return X_poly\n",
    "\n",
    "def fit_phi_poly(y, xvars, degree):\n",
    "    #Get number of observations (n) and number of independent variables (k)\n",
    "    #y = y.to_numpy()\n",
    "    #DATA = DATA.to_numpy()\n",
    "    if xvars.ndim == 1:\n",
    "        xvars.reshape(1, -1)\n",
    "    # Get the number of samples (n) and number of features (m) from X\n",
    "    n_samples, n_features = xvars.shape\n",
    "    \n",
    "    # Start with a column of ones for the intercept term\n",
    "    X_poly = np.ones((n_samples, 1))\n",
    "\n",
    "    #Create iterator used to construct polynomial terms\n",
    "    polynomial_terms = poly_terms(n_features, degree)\n",
    "    \n",
    "    # Generate polynomial terms and interaction terms up to 4th degree\n",
    "    for terms in  polynomial_terms:  # For degrees 1 to 4\n",
    "            X_poly = np.hstack((X_poly, np.prod(xvars[:, terms], axis=1).reshape(-1, 1)))\n",
    "    \n",
    "    # Compute the coefficients using the normal equation: beta = (X.T * X)^(-1) * X.T * y\n",
    "    XT_X = X_poly.T @ X_poly\n",
    "    XT_X_inv = np.linalg.inv(XT_X)\n",
    "    XT_y = X_poly.T @ y\n",
    "    gamma = XT_X_inv @ XT_y\n",
    "\n",
    "    return gamma\n",
    "\n",
    "\n",
    "#Create the matrix MT, which is used for year-by-year evaluation of the regression moments. \n",
    "def time_indexing(df, X_poly, degree = 2):\n",
    "    #Times and indexing\n",
    "    times = np.unique(df['t']) #get unique times in the sample\n",
    "    T = len(times) #Number of unique times in the sample\n",
    "    NPolyTerms= X_poly.shape[1] #Number of terms in the polynomial\n",
    "    time_to_index = {time: idx for idx, time in enumerate(times)} # Create a dictionary mapping time values to the row index in G\n",
    "    #Create a Nobs*T matrix of time dummies, used to create the error terms for GMM\n",
    "    # Initialize the dummy matrix\n",
    "    time_dummies = np.zeros((X_poly.shape[0], T))\n",
    "    for i, t in enumerate(df['t']):\n",
    "        time_index = np.where(times == t)[0][0]  # Find the index of the time in unique_times\n",
    "        time_dummies[i, time_index] = 1\n",
    "    #Previous time dummies\n",
    "    time_dummies_prev = np.zeros((X_poly.shape[0], T))\n",
    "    for i, t in enumerate(df['tprev']):\n",
    "        if not np.isnan(t):\n",
    "            time_index = np.where(times == t)[0][0]  # Find the index of the time in unique_times\n",
    "            time_dummies_prev[i, time_index] = 1\n",
    "    return T, NPolyTerms, times, time_to_index, time_dummies, time_dummies_prev  \n",
    "\n",
    "\n",
    "\n",
    "#creates the first term in the moment restrictions:\n",
    "def moment_error_ACF(theta, df, X_poly, degree = 2):\n",
    "    Nobs = df.shape[0]\n",
    "    #Get useful indexes\n",
    "    T, NPolyTerms, times, time_to_index, time_dummies, time_dummies_prev = time_indexing(df, X_poly, degree=2)\n",
    "    #Reshape parameters theta. \n",
    "    betas = theta[:4] #extract beta_0, beta_k, beta_l, and rho\n",
    "    gammas = theta[4:] #extract the guesses for the polynomial fit coefficeints (gammas).\n",
    "    #Reshaope the gammas into a dictionary, indexed by time t of the observations. \n",
    "    Gamma_1_to_T = gammas.reshape(T, NPolyTerms) #This fills rows with K observations, then columns. \n",
    "    #Now, construct a mapping from GAMMA, whose rows are indexed by T, to the times in the sample\n",
    "    GAMMA = np.vstack([Gamma_1_to_T[time_to_index[t]] for t in df['t']])\n",
    "    #Now, evaluate Phi given the thetas.\n",
    "    #To do this, elementwise-multiply the X with the polynomal coefficients in GAMMA. Sum the rows. \n",
    "    df['Phi'] = np.sum(X_poly*GAMMA, axis = 1)\n",
    "    y_minus_Phi = df['y'] - df['Phi']\n",
    "    Y_MINUS_PHI = np.repeat(y_minus_Phi.to_numpy()[:, np.newaxis], T, axis=1)\n",
    "    #Matrix of errors corresponding with regression moments (Nobs x T)\n",
    "    Epsilon = (Y_MINUS_PHI*time_dummies).T@ (X_poly)\n",
    "    #Here, we want to unravel the Epsilon matrix so gammas are sorted into vectors by t. \n",
    "    epsilons = Epsilon.reshape(Epsilon.size)\n",
    "    #Lagged values of Phi\n",
    "    df['Phiprev'] = df.groupby('firm_id')['Phi'].shift(1)\n",
    "    #Now calculate the moment restrictions vector for the betas. \n",
    "    moments_betas = (df['y'] - theta[0] - theta[1]*df['k'] - theta[2]*df['l'] - \n",
    "             theta[3]*(df['Phiprev'] - theta[0] - theta[1]*df['kprev'] - theta[2]*df['lprev'] ) )\n",
    "    #remove nans (associated with the lag) -- this is ok because we're just using this vector as part of a dot product. \n",
    "    moments_betas = np.nan_to_num(moments_betas, nan = 0)\n",
    "    #Matrix of exclusion restrictions\n",
    "    Vex = np.nan_to_num(np.vstack([\n",
    "        np.ones(Nobs), \n",
    "        df['k'].to_numpy(), \n",
    "        df['lprev'].to_numpy(),\n",
    "        df['Phiprev'].to_numpy()\n",
    "    ]),  nan=0)\n",
    "    #Evaluate the errors\n",
    "    err_betas = Vex@moments_betas\n",
    "    #Put together all of the errors into a single vector. \n",
    "    error_vec = np.concatenate((err_betas, epsilons))\n",
    "    return error_vec\n",
    "\n",
    "def gmm_obj_ACF(theta, df, X_poly, W):\n",
    "    #Arguments\n",
    "    #Get the vector h(theta, y, k, l)\n",
    "    moment_error = moment_error_ACF(theta, df, X_poly, degree)\n",
    "    #Calculate the weighted sum of the error using the weight matrix, W\n",
    "    obj = moment_error.T@W@moment_error\n",
    "    return obj\n",
    "\n",
    "def gradient_ACF(theta, df, X_poly, W):\n",
    "    #A lot of this code is repeated from moment_error_ACF -- Clean up later\n",
    "    Nobs = df.shape[0]\n",
    "    #Get useful indexes\n",
    "    T, NPolyTerms, times, time_to_index, time_dummies, time_dummies_prev= time_indexing(df, X_poly, degree=2)\n",
    "    #Reshape parameters theta. \n",
    "    betas = theta[:4] #extract beta_0, beta_k, beta_l, and rho\n",
    "    gammas = theta[4:] #extract the guesses for the polynomial fit coefficeints (gammas).\n",
    "    #Reshaope the gammas into a dictionary, indexed by time t of the observations. \n",
    "    Gamma_1_to_T = gammas.reshape(T, NPolyTerms) #This fills rows with K observations, then columns. \n",
    "    #Now, construct a mapping from GAMMA, whose rows are indexed by T, to the times in the sample\n",
    "    GAMMA = np.vstack([Gamma_1_to_T[time_to_index[t]] for t in df['t']])\n",
    "    #Now, evaluate Phi given the thetas.\n",
    "    #To do this, elementwise-multiply the X with the polynomal coefficients in GAMMA. Sum the rows. \n",
    "    df['Phi'] = np.sum(X_poly*GAMMA, axis = 1)\n",
    "    y_minus_Phi = df['y'] - df['Phi']\n",
    "    Y_MINUS_PHI = np.repeat(y_minus_Phi.to_numpy()[:, np.newaxis], 10, axis=1)\n",
    "    #Matrix of errors corresponding with regression moments (Nobs x T)\n",
    "    #Epsilon = (X_poly).T @ (Y_MINUS_PHI*time_dummies)\n",
    "    #Lagged values of Phi\n",
    "    df['Phiprev'] = df.groupby('firm_id')['Phi'].shift(1)\n",
    "    #Now calculate the moment restrictions vector for the betas. \n",
    "    df['moments_betas'] = (df['y'] - theta[0] - theta[1]*df['k'] - theta[2]*df['l'] - \n",
    "             theta[3]*(df['Phiprev'] - theta[0] - theta[1]*df['kprev'] - theta[2]*df['lprev'] ) )\n",
    "\n",
    "    #Now we have Phi, Phiprev, and \"moments_betas\"(h). \n",
    "    #Next, calculate the Jacobian \n",
    "    Jac = np.zeros((theta.size, theta.size))\n",
    "\n",
    "    #Create dictionary of (polynomial design matrices) indexed by time, then convert it to a block diagonal matrix.\n",
    "    #This represents the portion of the Jacobian for the regression moments. \n",
    "    XTX_dict = {}\n",
    "    for yr in times:\n",
    "        XTX_dict[yr] = X_poly[df['t']==yr].T@X_poly[df['t']==yr]\n",
    "    XTX_list = list(XTX_dict.values())\n",
    "    Jac_bottomblock = -block_diag(*XTX_list)\n",
    "\n",
    "    #Next, create the portion of the Jacobian related to the moments which identify the betas.\n",
    "    #Matrix of exclusion restrictions\n",
    "    Vex = np.nan_to_num(np.vstack([\n",
    "        np.ones(Nobs), \n",
    "        df['k'].to_numpy(), \n",
    "        df['lprev'].to_numpy(),\n",
    "        df['Phiprev'].to_numpy()\n",
    "    ]),  nan=0)\n",
    "    #now get dMomentsBeta/dBeta\n",
    "    #Partial derivatives of h\n",
    "    Dh = np.nan_to_num(np.vstack(\n",
    "        [\n",
    "         np.ones(Nobs)*(-1 + theta[3]), #dh/dbeta0  \n",
    "         -df['k'] + theta[3]*df['kprev'],             #dh/dbetak\n",
    "         -df['l'] + theta[3]*df['lprev'],             #dh/dbetal\n",
    "         -(df['Phiprev'] - theta[0] - theta[1]*df['kprev'] - theta[2]*df['lprev'])\n",
    "        ]\n",
    "    ),  nan=0).T\n",
    "    #Get the vector h(theta, y, k, l)\n",
    "    moment_error = moment_error_ACF(theta, df, X_poly, degree)\n",
    "    #Calculate the weighted sum of the error using the weight matrix, W\n",
    "    obj = moment_error.T@W@moment_error\n",
    "    #now for dMomentsBeta/dGamma\n",
    "    #Need the polynomial design matrix associated with kprev, lprev, mprev    \n",
    "    xvars_prev = df[['kprev', 'lprev', 'mprev']].to_numpy()\n",
    "    Xprev_poly = poly_design_matrix(xvars_prev, degree)\n",
    "    # Set rows with any NaN values to zeros\n",
    "    Xprev_poly[np.isnan(Xprev_poly).any(axis=1)] = 0\n",
    "    # Repeat X for elementwise multiplication\n",
    "    Xprev_poly_repeated = np.tile(Xprev_poly, (1, T))  # (3x6) for this case\n",
    "    #Create matrix of time dummies used to repeat the xprev_poly matrix. \n",
    "    time_dummies_prev_repeated = np.repeat(time_dummies_prev, Xprev_poly.shape[1], axis=1)\n",
    "    # Jacobian's upper block: the derivative of the \"beta moments\" w.r.t. the \"gammmas\"\n",
    "    block_dgamma = Xprev_poly_repeated*time_dummies_prev_repeated  # (3x6) for this case\n",
    "\n",
    "    #Get the top block of the Jacobian (except one missing term)\n",
    "    Jac_topblock_almost = Vex@np.hstack((Dh, -theta[3]*block_dgamma))\n",
    "    #Final missing term      \"h\" function here \n",
    "    Jac_topblock_lastrow = (np.nan_to_num(df['moments_betas'].to_numpy(), nan=0)).T@block_dgamma\n",
    "    #Combine\n",
    "    Jac_topblock = Jac_topblock_almost\n",
    "    Jac_topblock[3, 4:] = Jac_topblock[3, 4:] + Jac_topblock_lastrow \n",
    "    #Fill in the full Jacobian\n",
    "    Jac[:4, :] = Jac_topblock\n",
    "    Jac[4:, 4:] = Jac_bottomblock\n",
    "    #Now that we have the Jacobian, calculate the gradient. \n",
    "    Grad = (2*Jac.T @ W @ moment_error)\n",
    "    return Grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.68385631e+10, -2.13269492e+11, -8.70841809e+10, -1.30714698e+12,\n",
       "        1.14530458e+10,  1.39743892e+11,  6.00136791e+10,  1.51844895e+11,\n",
       "        1.73765440e+12,  7.51758696e+11,  1.88001366e+12,  3.29871166e+11,\n",
       "        8.15950490e+11,  2.04671928e+12,  3.12138778e+10,  3.84263158e+11,\n",
       "        1.58522968e+11,  4.12343946e+11,  4.85051321e+12,  2.02010701e+12,\n",
       "        5.17201959e+12,  8.54746852e+11,  2.15831421e+12,  5.54287044e+12,\n",
       "        5.42405787e+10,  6.83325045e+11,  2.81783332e+11,  7.23388357e+11,\n",
       "        8.82227865e+12,  3.67164285e+12,  9.27700606e+12,  1.55597427e+12,\n",
       "        3.86886169e+12,  9.79919337e+12,  5.42898135e+10,  6.91147531e+11,\n",
       "        2.83734139e+11,  7.23310666e+11,  9.01469546e+12,  3.73295042e+12,\n",
       "        9.37035424e+12,  1.57107026e+12,  3.88389970e+12,  9.78491443e+12,\n",
       "        7.30585585e+10,  9.29114666e+11,  3.80826088e+11,  9.80150033e+11,\n",
       "        1.20766345e+13,  4.99600351e+12,  1.26734184e+13,  2.10099028e+12,\n",
       "        5.24589443e+12,  1.33430843e+13,  7.71586102e+10,  9.84655957e+11,\n",
       "        4.03052271e+11,  1.04137378e+12,  1.28442767e+13,  5.30199778e+12,\n",
       "        1.35049081e+13,  2.22730054e+12,  5.57696277e+12,  1.42506207e+13,\n",
       "        8.68147579e+10,  1.11204955e+12,  4.50679940e+11,  1.17222321e+12,\n",
       "        1.45793716e+13,  5.95857798e+12,  1.52629826e+13,  2.47899214e+12,\n",
       "        6.24023338e+12,  1.60489785e+13,  8.70858467e+10,  1.10893773e+12,\n",
       "        4.50176456e+11,  1.17996714e+12,  1.44161088e+13,  5.90101091e+12,\n",
       "        1.52536453e+13,  2.46093935e+12,  6.24729811e+12,  1.62001091e+13,\n",
       "        8.07994447e+10,  1.02882866e+12,  4.13063099e+11,  1.09422201e+12,\n",
       "        1.33708421e+13,  5.41407072e+12,  1.41440839e+13,  2.23649829e+12,\n",
       "        5.73132464e+12,  1.50207327e+13,  5.56845388e+10,  7.14484596e+11,\n",
       "        2.86838958e+11,  7.61262430e+11,  9.34675479e+12,  3.78459352e+12,\n",
       "        9.90669258e+12,  1.55984877e+12,  4.01263494e+12,  1.05401334e+13])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting objects we will use in estimation\n",
    "degree = 2\n",
    "xvars = df[['k', 'l', 'm']].to_numpy()\n",
    "\n",
    "#Guessing \n",
    "#gamma_guess = fit_phi_poly(df['y'].to_numpy(), xvars, degree)\n",
    "\n",
    "X_poly = poly_design_matrix(xvars, degree)\n",
    "T, NPolyTerms, times, time_to_index, time_dummies, time_dummies_prev  = time_indexing(df, X_poly, degree)\n",
    "#Initial parameter guess\n",
    "theta0 = np.ones(4 + T*NPolyTerms)/10\n",
    "#GMM weighting matrix\n",
    "W0 = np.eye(4 + T*NPolyTerms)\n",
    "#\n",
    "\n",
    "#testing\n",
    "\n",
    "err = gmm_obj_ACF(theta0, df, X_poly, W0)\n",
    "err\n",
    "Grad = gradient_ACF(theta0, df, X_poly, W0)\n",
    "Grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, use a minimization routine, with the Jacobian, to optimize for theta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_args = (df, X_poly, W0)\n",
    "theta0 =  np.zeros(4 + T*NPolyTerms)\n",
    "theta0[:4]=1\n",
    "#Solving using my own gradient\n",
    "theta_results_grad = opt.minimize(gmm_obj_ACF, theta0, args=gmm_args,\n",
    "                       tol=1e-14, jac=gradient_ACF, method='L-BFGS-B')\n",
    "#Solving without providing a gradient\n",
    "#theta_results_nograd = opt.minimize(gmm_obj_ACF, theta0, args=gmm_args,\n",
    "#                        tol=1e-14, method='L-BFGS-B',  options={'maxiter': 200})\n",
    "res = theta_results_grad.x\n",
    "#theta_results_nograd.fun\n",
    "#gmm_obj_ACF(res, df, X_poly, W0)\n",
    "res\n",
    "#theta_results_grad.x, theta_results_nograd.x\n",
    "#theta_results = theta_results_grad.x\n",
    "\n",
    "#gmm_obj_ACF(theta_results, args_ACF, Vex, W0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
